TODO:

- Multi-Label Training und Evaluation umsetzen

- Verschiendene Losses Testen, siehe
    - https://towardsdatascience.com/handling-class-imbalanced-data-using-a-loss-specifically-made-for-it-6e58fd65ffab
    - https://pytorch.org/docs/stable/generated/torch.nn.MultiLabelSoftMarginLoss.html#torch.nn.MultiLabelSoftMarginLoss
    - Hamming loss (minimiert die Hamming Distance): https://scikit-learn.org/stable/modules/model_evaluation.html#hamming-loss
    - Class Balanced Loss: https://github.com/vandit15/Class-balanced-loss-pytorch/blob/master/class_balanced_loss.py
    - Softmax for Multilabel Classification (Faceboook): https://gombru.github.io/2018/05/23/cross_entropy_loss/

- Hyperparameter-Tuning: Frameworks/Libs finden und für eine entscheiden
    - Ray Tune: https://docs.ray.io/en/master/tune/index.html
    - Optuna: https://github.com/optuna/optuna
    - Hyperopt: https://github.com/hyperopt/hyperopt

- Mehr Metriken wegspeichern, nicht nur Loss und die Accuracy:
    * So viele wie möglich  -> Acc, Precision, Recall, F1, AUC/ROC, 4 Felder für jede Klasse (FP, FN, TP, TN)
                            -> Weitere, eigene Ideen: PR-Curve
    * Beim Testen für den jeweilgen Datensatz, welche WK er für welche Klasse vorhersagt (nicht beim Validieren, einmal am Ende)

- Mit Tensorboard und den zur Verfügung stehenden Visualisierung befassen; Zusammenspiel mit Framework verstehen

- Mapping von Orderstruktur in /saved auf mehr Informationen, damit es auch in Monaten noch nachvollziehbar ist
    * Neues Dokument im Cherrytree anlegen und dort das Mapping erstellen
    * Dazu schreiben, was man da speziell gemacht hat -> Codierung überlegen, wie man einzelne Läufe anhand des Namens erkennt
    * Beispielsweise enthält die Codierung von Robert folgende Elemente (teils als Zahlencode):
      Modellname, Pretrain oder FineTune, Datensatz, Modelltyp, feine Aenderung

- Daten nach der Vorverarbeitung plotten und anschauen
    * Passt das so, wie es aus dem Dataset kommt?
    * Ist bei der Vorverarbeitung was schief gegangen? Fehlen Werte?

- In der _save_checkpoint Methode des BaseTrainers  wird nur der Klassenname gespeichert, der Code hinter dem Modell
  muss aber auch gespeichert werden, da er sich mit der Zeit ändert:
    * Mgl. 1: Modelle unterschiedlich benennen und mit Copy&Paste arbeiten -> wird schnell unübersichtlich
    * Mgl. 2: Wie Robert pro Modell ein eigenen Branch im Git eröffnen und immer darauf arbeiten bzw. hin und her switchen

- Konfigurierbare Modelle erstellen; Parameter nicht hard-coden!
    * Für Hyperparam-Studie ist es besser, die Werte in die Config zu packen und nur dort zu ändern
    * Es sollte möglich sein, den Kontext nur anhand der Config wiederherstellen zu können

- Set number of workers in the config.json to a higher number (e.g. 2) after finishing the debugging


NEXT STEPS:
- Logging verstehen: DONE
- Metriken erweitern
- Tensorboard verstehen und ggf erweitern
- Verwaltung, Sichern und Laden verschiedener Architekturen
- DataLoader und Dataset für neues Preprocessing anpassen: DONE



Fehlersuche:
tensoren detachen und plotten (das, was das Netz bekommt im Forward)

BiRNN + Attention rausnehmen, evtl Attention als Self-Attention


Daten nach dem CNN - noch viele 0er an den Rändern?
Evtl Probleme mit RNN, eugt nur wenn nicht richitg initialisiert


Attention nochmal anschauen: Shapes der Attentionweights

Attentionmatrix in Heatmap plotten - sollte nicht gleichverteilt sein


Cardiologist level arrythmia detection with CNNs (Andrew Ng)

Daten zwischen 0 und 1 skalieren,
Daten auf Outlier filtern, sonst wird Skalierung zerhauen
-> Robert Git Repo


Shell Skript und Anleitung wie man Netz zum Laufen bekommt
(requirements.txt)
- Daten laden (aber kein aufäwndiges Skript), am besten einfach in die Nextcloud und dann einen Link, von wo man sie kopieren kann


(0.773 + 0.857 + 0.687 + 0.554 + 0.886 + 0.574 + 0.639 + 0.300 + 0.636)/9
(0.708 + 0.833 + 0.821 + 0.471 + 0.879 + 0.528 + 0.624 + 0.242 + 0.656)/9
(0.899 + 0.843 + 0.667 + 0.744 + 0.886 + 0.807 + 0.807 + 0.548 + 0.833)/9
(0.757 + 0.851 + 0.816 + 0.654 + 0.865 + 0.777 + 0.809 + 0.405 + 0.812)/9

(0.909 + 0.916 + 0.939 + 0.849 + 0.951 + 0.989 + 0.842 + 0.750 + 0.926)/9
(0.929 + 0.920 + 0.979 + 0.796 + 0.934 + 0.932 + 0.856 + 0.646 + 0.867)/9
(0.881 + 0.862 + 0.769 + 0.731 + 0.876 + 0.864 + 0.793 + 0.415 + 0.819)/9
(0.852 + 0.870 + 0.738 + 0.667 + 0.840 + 0.818 + 0.769 + 0.395 + 0.742)/9

(0.836 + 0.885 + 0.793 + 0.671 + 0.917 + 0.727 + 0.727 + 0.429 + 0.754)/9
(0.804 + 0.875 + 0.893 + 0.592 + 0.906 + 0.674 + 0.722 + 0.352 + 0.747)/9
(0.890 + 0.853 + 0.714 + 0.737 + 0.881 + 0.835 + 0.800 + 0.472 + 0.826)/9
(0.801 + 0.860 + 0.775 + 0.660 + 0.853 + 0.797 + 0.788 + 0.400 + 0.776)/9

(0.979 + 0.983 + 0.978 + 0.951 + 0.985 + 0.978 + 0.945 + 0.939 + 0.983)/9
(0.980 + 0.979 + 0.986 + 0.946 + 0.983 + 0.964 + 0.954 + 0.855 + 0.974)/9
(0.977 + 0.984 + 0.963 + 0.949 + 0.978 + 0.980 + 0.950 + 0.897 + 0.977)/9
(0.972 + 0.975 + 0.974 + 0.933 + 0.972 + 0.963 + 0.941 + 0.844 + 0.968)/9

(0.960 + 0.957 + 0.983 + 0.924 + 0.954 + 0.900 + 0.919 + 0.936 + 0.947)/9
(0.953 + 0.952 + 0.992 + 0.910 + 0.946 + 0.874 + 0.920 + 0.917 + 0.939)/9
(0.881 + 0.862 + 0.769 + 0.731 + 0.876 + 0.864 + 0.793 + 0.415 + 0.819)/9
(0.852 + 0.870 + 0.738 + 0.667 + 0.840 + 0.818 + 0.769 + 0.395 + 0.742)/9


Normal & \Large{$N_{11}$} & \Large{$N_{12}$} & \Large{$N_{13}$} & \Large{$N_{14}$} & \Large{$N_{15}$} & \Large{$N_{16}$} & \Large{$N_{17}$} & \Large{$N_{18}$} & \Large{$N_{19}$} & \Large{$N_{1X}$} \\
AF	   & \Large{$N_{21}$} & \Large{$N_{22}$} & \Large{$N_{23}$} & \Large{$N_{24}$} & \Large{$N_{25}$} & \Large{$N_{26}$} & \Large{$N_{27}$} & \Large{$N_{28}$} & \Large{$N_{29}$} & \Large{$N_{2X}$} \\
I-AVB  & \Large{$N_{31}$} & \Large{$N_{32}$} & \Large{$N_{33}$} & \Large{$N_{34}$} & \Large{$N_{35}$} & \Large{$N_{36}$} & \Large{$N_{37}$} & \Large{$N_{38}$} & \Large{$N_{39}$} & \Large{$N_{3X}$} \\
LBBB   & \Large{$N_{41}$} & \Large{$N_{42}$} & \Large{$N_{43}$} & \Large{$N_{44}$} & \Large{$N_{45}$} & \Large{$N_{46}$} & \Large{$N_{47}$} & \Large{$N_{48}$} & \Large{$N_{49}$} & \Large{$N_{4X}$} \\
RBBB   & \Large{$N_{51}$} & \Large{$N_{52}$} & \Large{$N_{53}$} & \Large{$N_{54}$} & \Large{$N_{55}$} & \Large{$N_{56}$} & \Large{$N_{57}$} & \Large{$N_{58}$} & \Large{$N_{59}$} & \Large{$N_{5X}$} \\
PAC    & \Large{$N_{61}$} & \Large{$N_{62}$} & \Large{$N_{63}$} & \Large{$N_{64}$} & \Large{$N_{65}$} & \Large{$N_{66}$} & \Large{$N_{67}$} & \Large{$N_{68}$} & \Large{$N_{69}$} & \Large{$N_{6X}$} \\
PVC    & \Large{$N_{71}$} & \Large{$N_{72}$} & \Large{$N_{73}$} & \Large{$N_{74}$} & \Large{$N_{75}$} & \Large{$N_{76}$} & \Large{$N_{77}$} & \Large{$N_{78}$} & \Large{$N_{79}$} & \Large{$N_{7X}$} \\
STD    & \Large{$N_{81}$} & \Large{$N_{82}$} & \Large{$N_{83}$} & \Large{$N_{84}$} & \Large{$N_{85}$} & \Large{$N_{86}$} & \Large{$N_{87}$} & \Large{$N_{88}$} & \Large{$N_{89}$} & \Large{$N_{8X}$} \\
STE    & \Large{$N_{91}$} & \Large{$N_{92}$} & \Large{$N_{93}$} & \Large{$N_{94}$} & \Large{$N_{95}$} & \Large{$N_{96}$} & \Large{$N_{97}$} & \Large{$N_{98}$} & \Large{$N_{99}$} & \Large{$N_{9X}$} \\
\midrule
Total  & \Large{$N_{X1}$} & \Large{$N_{X2}$} & \Large{$N_{X3}$} & \Large{$N_{X4}$} & \Large{$N_{X5}$} & \Large{$N_{X6}$} & \Large{$N_{X7}$} & \Large{$N_{X8}$} & \Large{$N_{X9}$} &  \\